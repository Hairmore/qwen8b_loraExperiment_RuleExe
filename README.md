# Qwen-8B LoRA Fine-tuning

éµå¾ªæ ‡å‡†åŒ–å®éªŒæ—¥å¿—ç®¡ç†è§„èŒƒçš„ Qwen æ¨¡å‹ LoRA å¾®è°ƒä»£ç ã€‚

## ğŸ¯ å®éªŒæ—¥å¿—è§„èŒƒ

æœ¬é¡¹ç›®ä¸¥æ ¼éµå¾ªä»¥ä¸‹è§„èŒƒï¼š

### 1ï¸âƒ£ é…ç½®è§£è€¦ (Config Decoupling)
- æ‰€æœ‰è¶…å‚æ•°é€šè¿‡ `config.yaml` é…ç½®
- æ”¯æŒå‘½ä»¤è¡Œå‚æ•°è¦†ç›–
- æ¯æ¬¡å®éªŒè‡ªåŠ¨ä¿å­˜é…ç½®å‰¯æœ¬

### 2ï¸âƒ£ ä»£ç æŒ‡çº¹ (Git Commit ID)
- è‡ªåŠ¨è®°å½• Git Commit Hash
- æ£€æµ‹æœªæäº¤çš„ä»£ç ä¿®æ”¹
- æ—¥å¿—å¼€å¤´æ‰“å°ä»£ç ç‰ˆæœ¬

### 3ï¸âƒ£ æ ‡å‡†åŒ–ç›®å½•ç»“æ„ (Structure)
```
work_dirs/
â””â”€â”€ 20251130_qwen257binstruct_lora_r16_lr0.0001/
    â”œâ”€â”€ config.yaml          # é…ç½®å‰¯æœ¬
    â”œâ”€â”€ log.txt              # å®Œæ•´æ—¥å¿—
    â”œâ”€â”€ train.py             # ä»£ç å¤‡ä»½
    â”œâ”€â”€ best_model/          # æœ€ä¼˜æƒé‡
    â”‚   â”œâ”€â”€ adapter_config.json
    â”‚   â””â”€â”€ adapter_model.safetensors
    â”œâ”€â”€ checkpoints/         # è®­ç»ƒæ£€æŸ¥ç‚¹
    â””â”€â”€ tb_logs/             # TensorBoard æ—¥å¿—
```

### 4ï¸âƒ£ æ—¥å¿—å†…å®¹æ ¸å¯¹è¡¨ (Checklist)
`log.txt` å¼€å¤´åŒ…å«ï¼š
1. **Command**: å®Œæ•´è¿è¡ŒæŒ‡ä»¤
2. **Environment**: PyTorch/CUDA/GPU ä¿¡æ¯
3. **Seed**: éšæœºç§å­
4. **Git Hash**: ä»£ç ç‰ˆæœ¬å·
5. **Config**: æ‰€æœ‰è¶…å‚æ•°

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®
æ•°æ®æ ¼å¼ (JSONL):
```json
{"instruction": "é—®é¢˜", "input": "å¯é€‰è¾“å…¥", "output": "æœŸæœ›è¾“å‡º"}
```

### 3. ä¿®æ”¹é…ç½®
ç¼–è¾‘ `config.yaml` è®¾ç½®æ¨¡å‹è·¯å¾„ã€æ•°æ®è·¯å¾„ç­‰ã€‚

### 4. å¼€å§‹è®­ç»ƒ
```bash
# ä½¿ç”¨é»˜è®¤é…ç½®
python train_qwen8b_lora.py --config config.yaml

# å‘½ä»¤è¡Œè¦†ç›–å‚æ•°
python train_qwen8b_lora.py --config config.yaml --lr 5e-5 --epochs 3

# è‡ªå®šä¹‰å®éªŒåç§°
python train_qwen8b_lora.py --config config.yaml --exp_name my_experiment
```

## ğŸ“Š SwanLab ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¼šè‡ªåŠ¨è®°å½•åˆ° SwanLabï¼š
- è®­ç»ƒ Loss
- å­¦ä¹ ç‡å˜åŒ–
- éªŒè¯æŒ‡æ ‡

æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ï¼š
```bash
swanlab watch
```

## âš™ï¸ é…ç½®è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| batch_size | 8 | æ‰¹æ¬¡å¤§å° |
| learning_rate | 1e-4 | å­¦ä¹ ç‡ |
| n_epochs | 2 | è®­ç»ƒè½®æ•° |
| lora_rank | 16 | LoRA ç§© |
| lora_alpha | 32 | LoRA alpha |
| lora_dropout | 0.15 | LoRA dropout |
| max_length | 8192 | æœ€å¤§åºåˆ—é•¿åº¦ |
| seed | 42 | éšæœºç§å­ |

## ğŸ“ å¤ç°å®éªŒ

æ‰¾åˆ°ä½ æƒ³å¤ç°çš„å®éªŒç›®å½•ï¼Œä¾‹å¦‚ `work_dirs/20251130_xxx/`:

```bash
# 1. æ¢å¤ä»£ç ç‰ˆæœ¬
git checkout <log.txt ä¸­çš„ Git Hash>

# 2. ä½¿ç”¨ä¿å­˜çš„é…ç½®
python train_qwen8b_lora.py --config work_dirs/20251130_xxx/config.yaml
```

## ğŸ”„ å¤šç»„è¶…å‚æ•°å®éªŒ

### é…ç½®è¶…å‚æ•°æœç´¢

ç¼–è¾‘ `sweep_config.yaml`ï¼š

```yaml
# ç½‘æ ¼æœç´¢æ¨¡å¼
search_mode: "grid_search"

grid_search:
  learning_rate: [1.0e-4, 5.0e-5, 1.0e-5]
  lora_rank: [8, 16, 32]
  batch_size: [4, 8]
  n_epochs: [2, 3]
```

æˆ–è€…æ‰‹åŠ¨æŒ‡å®šå®éªŒç»„ï¼š

```yaml
search_mode: "manual"

manual_experiments:
  - name: "baseline"
    learning_rate: 1.0e-4
    lora_rank: 16
    batch_size: 8
    n_epochs: 2

  - name: "high_rank"
    learning_rate: 5.0e-5
    lora_rank: 64
    batch_size: 4
    n_epochs: 3
```

### è¿è¡Œå¤šç»„å®éªŒ

```bash
# é¢„è§ˆå®éªŒè®¡åˆ’ï¼ˆä¸å®é™…è¿è¡Œï¼‰
python run_sweep.py --config sweep_config.yaml --dry-run

# å¼€å§‹è¿è¡Œæ‰€æœ‰å®éªŒ
python run_sweep.py --config sweep_config.yaml

# ä»ç¬¬ 5 ä¸ªå®éªŒå¼€å§‹ï¼ˆæ–­ç‚¹ç»­è·‘ï¼‰
python run_sweep.py --config sweep_config.yaml --start-from 5
```

### å®éªŒç»“æœæ±‡æ€»

è¿è¡Œå®Œæˆåï¼Œè‡ªåŠ¨ç”Ÿæˆï¼š
- `work_dirs/sweep_summary.md` - Markdown æ±‡æ€»æŠ¥å‘Š
- `work_dirs/sweep_results.json` - JSON æ ¼å¼å®Œæ•´ç»“æœ

æŠ¥å‘ŠåŒ…å«ï¼š
- æ‰€æœ‰å®éªŒçš„çŠ¶æ€ã€è€—æ—¶ã€Final Loss
- æœ€ä½³å®éªŒçš„é…ç½®è¯¦æƒ…
- å¤±è´¥å®éªŒçš„é”™è¯¯ä¿¡æ¯

## ğŸ“ é¡¹ç›®ç»“æ„

```
qwen8b_lora/
â”œâ”€â”€ config.yaml              # å•æ¬¡å®éªŒé…ç½®
â”œâ”€â”€ sweep_config.yaml        # å¤šå®éªŒè¶…å‚æ•°æœç´¢é…ç½®
â”œâ”€â”€ train_qwen8b_lora.py     # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ run_sweep.py             # å¤šå®éªŒè¿è¡Œå™¨
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ data/
â”‚   â””â”€â”€ train.jsonl          # è®­ç»ƒæ•°æ®
â””â”€â”€ work_dirs/               # å®éªŒè¾“å‡ºç›®å½•
    â”œâ”€â”€ sweep_summary.md     # æ±‡æ€»æŠ¥å‘Š
    â”œâ”€â”€ sweep_results.json   # å®Œæ•´ç»“æœ
    â””â”€â”€ 20251130_xxx/        # å„å®éªŒç›®å½•
```
